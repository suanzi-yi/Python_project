# # import requests
# from bs4 import BeautifulSoup
# import  urllib
# import urllib.parse
# data1={'username':'qiyue'}
# data=urllib.parse.urlencode(data1)
# print(data)
# import re
#
# # headers={}
# # #获取响应
# # head={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36"}
# # url="http://www.baidu.com"
# # respone=requests.get(url,headers=head)
# # # print(respone.status_code)
# # # print(respone.encoding)
# # # print(type(respone.encoding))
# # # print(respone.apparent_encoding)
# # # print(type(respone.apparent_encoding))
# # # # print(respone.text)
# # # print(type(respone.text))
# # soup=BeautifulSoup(respone.content,'lxml')
# # print(soup.a)
# # a=soup.find_all('a')
# # print(a)
# # # print(soup.prettify())
# # for b in soup.find_all('a'):
# #
# #     print(soup.b)
# #     print(type(soup.b))
# #     print(soup.b.name)
# #     print(type(soup.b.name))
# #     print(soup.b.string)
# #     print(type(soup.b.string))
# #     print(soup.b.attrs['href'])
# #     print(type(soup.b.attrs['href']))
# #     print(soup.b.get('href'))
#
